{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2adbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:13.857438Z",
     "iopub.status.busy": "2024-08-05T10:42:13.857438Z",
     "iopub.status.idle": "2024-08-05T10:42:19.147063Z",
     "shell.execute_reply": "2024-08-05T10:42:19.147063Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5070e",
   "metadata": {},
   "source": [
    "# A. Manipular dados numéricos para algoritmos de Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47aa86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## A.1 O que é uma feature e a sua relação com os modelos de machine learning\n",
    "\n",
    "Uma feature, ou característica, é uma propriedade individual medível ou observável de um fenômeno sendo observado. No contexto de machine learning, uma feature é uma entrada para o modelo que contribui para a tomada de decisão ou para a previsão. Em termos mais práticos, as features podem ser vistas como colunas em uma tabela de dados, onde cada coluna representa um tipo específico de informação (como altura, peso, idade, etc.) que pode ser usada para prever um resultado (como o risco de uma doença, a classificação de um documento, etc.).\n",
    "\n",
    "Features podem ser quantitativas (numéricas) ou qualitativas (categóricas). A escolha e a qualidade das features são cruciais, pois impactam diretamente a capacidade do modelo de aprender padrões e realizar previsões precisas. A engenharia de features, que envolve a criação, transformação e seleção de features, é uma etapa essencial no desenvolvimento de modelos eficazes.\n",
    "\n",
    "## A.2 Escalares, vetores e espaços\n",
    "\n",
    "1. **Escalares**: Um escalar é um único valor numérico que pode ser um número real ou complexo. Ele representa uma quantidade unidimensional. Em machine learning, um escalar pode representar uma única medida ou valor, como a temperatura em um dado dia. Em álgebra linear, é frequentemente usado para multiplicar vetores e matrizes, alterando seu tamanho mas não sua direção.\n",
    "\n",
    "2. **Vetores**: Um vetor é uma quantidade que possui tanto magnitude quanto direção. Em machine learning, um vetor é uma sequência de números (escalares) dispostos em uma determinada ordem e frequentemente usados para representar uma amostra de dados, onde cada elemento do vetor é uma feature. Por exemplo, um vetor pode representar as características (features) de um paciente, como [idade, peso, pressão arterial]. E ainda um vetor em um espaço tridimensional pode ser representado como $[x, y, z]$ .\n",
    "\n",
    "3. **Espaços**: Em matemática, um espaço é um conjunto de vetores. Um espaço, especificamente um espaço vetorial, é um conjunto de vetores que podem ser adicionados uns aos outros e multiplicados por escalares para formar novos vetores dentro do mesmo espaço. Em machine learning, um espaço de features é o conjunto de todas as possíveis combinações de valores das features. Um vetor em um espaço de features representa uma amostra de dados, e a dimensionalidade do espaço corresponde ao número de features. Em machine learning, o espaço vetorial das features é onde as operações de modelagem acontecem. Este espaço pode ser de alta dimensão dependendo do número de features usadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576d131",
   "metadata": {},
   "source": [
    "## Binning, discretização ou Agrupamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614527db",
   "metadata": {},
   "source": [
    "\n",
    "### A.3 Discretização de variáveis contínuas por meio de quantização com bins fixos\n",
    "\n",
    "A discretização de variáveis contínuas é o processo de converter variáveis contínuas em variáveis discretas dividindo o intervalo contínuo em partes distintas chamadas \"bins\". Isso pode ser feito de várias maneiras, uma das quais é utilizando bins de largura fixa.\n",
    "\n",
    "**Exemplo em Python usando `pd.cut`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56e6cd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bin 7', 'Bin 4', 'Bin 2', 'Bin 7', 'Bin 9', ..., 'Bin 7', 'Bin 7', 'Bin 1', 'Bin 6', 'Bin 6']\n",
      "Length: 100\n",
      "Categories (10, object): ['Bin 1' < 'Bin 2' < 'Bin 3' < 'Bin 4' ... 'Bin 7' < 'Bin 8' < 'Bin 9' < 'Bin 10']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Discretização com bins de largura fixa\n",
    "bins = np.linspace(0, 100, 11)  # 10 bins de largura 10\n",
    "labels = [f'Bin {i}' for i in range(1, len(bins))]\n",
    "dados_discretizados = pd.cut(dados, bins=bins, labels=labels)\n",
    "\n",
    "print(dados_discretizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d002f7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins =np.linspace(0,10,11)\n",
    "plt.hist(dados_discretizados, bins=bins, edgecolor='k')\n",
    "plt.scatter(np.linspace(1,10,100), dados, alpha=0.5, c='red', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31c8ea",
   "metadata": {},
   "source": [
    "**Exemplo em Python usando `np.digitize`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7626a8ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:19.151061Z",
     "iopub.status.busy": "2024-08-05T10:42:19.151061Z",
     "iopub.status.idle": "2024-08-05T10:42:21.420942Z",
     "shell.execute_reply": "2024-08-05T10:42:21.420942Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 5 7 1 6 5 6 8 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados contínuos de exemplo\n",
    "dados = np.random.randn(1000)\n",
    "\n",
    "# Discretização em 10 bins fixos\n",
    "bins = np.linspace(np.min(dados), np.max(dados), 11)\n",
    "dados_discretizados = np.digitize(dados, bins)\n",
    "\n",
    "# Exibir os primeiros 10 dados discretizados\n",
    "print(dados_discretizados[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401a1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Data  Digitized\n",
      "0   0.919052         14\n",
      "1  -0.726624          8\n",
      "2  -1.162090          7\n",
      "3   0.594868         12\n",
      "4   0.636628         13\n",
      "5  -0.396675          9\n",
      "6   0.467916         12\n",
      "7  -0.616939          8\n",
      "8  -0.119856         10\n",
      "9  -1.721784          5\n",
      "10 -1.196313          7\n",
      "11 -0.562479          9\n",
      "12 -1.028785          7\n",
      "13  0.622541         13\n",
      "14 -0.504349          9\n",
      "15 -0.569871          9\n",
      "16  0.964153         14\n",
      "17 -0.872785          8\n",
      "18  0.082293         11\n",
      "19  1.916528         17\n",
      "20  1.506173         16\n",
      "21  0.581682         12\n",
      "22 -1.000842          7\n",
      "23 -0.320716          9\n",
      "24  0.411699         12\n",
      "25  0.068944         11\n",
      "26 -0.450129          9\n",
      "27 -0.385028          9\n",
      "28 -0.670549          8\n",
      "29  0.644110         13\n",
      "30  1.104224         14\n",
      "31 -0.103621         10\n",
      "32 -1.042038          7\n",
      "33 -0.564744          9\n",
      "34 -0.419079          9\n",
      "35 -0.488802          9\n",
      "36  1.247562         15\n",
      "37 -0.936889          7\n",
      "38 -0.491801          9\n",
      "39  0.119390         11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gerar dados contínuos de exemplo\n",
    "data = np.random.randn(1000)\n",
    "# Discretizar os dados em bins fixos\n",
    "bins = np.linspace(-3, 3, 21)\n",
    "\n",
    "digitized = np.digitize(data, bins)\n",
    "\n",
    "df = pd.DataFrame({'Data': data, 'Digitized': digitized})\n",
    "print(df.head(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169cba82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A.4 Discretização de variáveis contínuas por meio de quantização com bins variáveis\n",
    "\n",
    "A discretização com bins variáveis, ou \"quantiles\", divide os dados em intervalos de tal forma que cada bin contém aproximadamente o mesmo número de pontos de dados.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7a6d717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:21.425943Z",
     "iopub.status.busy": "2024-08-05T10:42:21.424947Z",
     "iopub.status.idle": "2024-08-05T10:42:21.466730Z",
     "shell.execute_reply": "2024-08-05T10:42:21.466730Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 3 0 4 9 7 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados contínuos de exemplo\n",
    "dados = np.random.randn(1000)\n",
    "\n",
    "# Discretização em 10 bins variáveis\n",
    "dados_discretizados, bins = pd.qcut(dados, q=10, retbins=True, labels=False)\n",
    "\n",
    "# Exibir os primeiros 10 dados discretizados\n",
    "print(dados_discretizados[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d797ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Data  Digitized\n",
      "0  0.585861          3\n",
      "1  1.348231          4\n",
      "2 -0.906309          1\n",
      "3 -1.374753          1\n",
      "4  0.424342          3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gerar dados contínuos de exemplo\n",
    "data = np.random.randn(1000)\n",
    "# Discretizar os dados em bins variáveis (quantis)\n",
    "bins = np.percentile(data, [0, 25, 50, 75, 100])\n",
    "digitized = np.digitize(data, bins)\n",
    "\n",
    "df = pd.DataFrame({'Data': data, 'Digitized': digitized})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9124dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A.5 Utilizar a FunctionTransformer do sklearn em uma variável\n",
    "\n",
    "A `FunctionTransformer` permite aplicar qualquer função de transformação aos dados, aplicando uma função customizada. Pode ser útil para aplicar transformações que não estão diretamente disponíveis nas outras classes de transformação do scikit-learn.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4055d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4]\n",
      " [ 9 16]\n",
      " [25 36]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Função customizada: quadrado dos valores\n",
    "transformer = FunctionTransformer(np.square)\n",
    "dados_transformados = transformer.transform(dados)\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "384efd7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:21.470725Z",
     "iopub.status.busy": "2024-08-05T10:42:21.469723Z",
     "iopub.status.idle": "2024-08-05T10:42:25.927320Z",
     "shell.execute_reply": "2024-08-05T10:42:25.926321Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.69314718]\n",
      " [1.09861229 1.38629436]\n",
      " [1.60943791 1.79175947]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[0, 1], [2, 3], [4, 5]])\n",
    "\n",
    "# Função de transformação: logaritmo natural\n",
    "transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "dados_transformados = transformer.transform(dados)\n",
    "\n",
    "# Exibir os dados transformados\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cade97",
   "metadata": {},
   "source": [
    "\n",
    "#### A.5.1. Transformações Logarítmicas\n",
    "Transformações logarítmicas podem ajudar a lidar com distribuições altamente assimétricas e reduzir a variabilidade dos dados.\n",
    "\n",
    "Comprime o intervalo de números grandes e expande o intervalo de números pequenos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da42e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  log_feature\n",
      "0        1     0.693147\n",
      "1       10     2.397895\n",
      "2      100     4.615121\n",
      "3     1000     6.908755\n",
      "4    10000     9.210440\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Exemplo de dados com distribuição assimétrica\n",
    "data = pd.DataFrame({'feature': [1, 10, 100, 1000, 10000]})\n",
    "\n",
    "# Aplicar transformação logarítmica\n",
    "data['log_feature'] = np.log1p(data['feature'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a4083d",
   "metadata": {},
   "source": [
    "#### A.5.2. Transformações de Raiz Quadrada\n",
    "A transformação de raiz quadrada pode estabilizar variâncias em conjuntos de dados com distribuições assimétricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec92fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature  sqrt_feature\n",
      "0        1      1.000000\n",
      "1       10      3.162278\n",
      "2      100     10.000000\n",
      "3     1000     31.622777\n",
      "4    10000    100.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Exemplo de dados\n",
    "data = pd.DataFrame({'feature': [1, 10, 100, 1000, 10000]})\n",
    "\n",
    "# Aplicar transformação de raiz quadrada\n",
    "data['sqrt_feature'] = np.sqrt(data['feature'])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671bb13",
   "metadata": {},
   "source": [
    "### A.6. Utilizar a PowerTransformer do sklearn em uma variável\n",
    "\n",
    "A `PowerTransformer` aplica uma transformação de potência (Box-Cox ou Yeo-Johnson) para estabilizar a variância e tornar os dados mais gaussianos.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fab609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02693441]\n",
      " [ 0.37888406]\n",
      " [-0.64599735]\n",
      " [-0.96359036]\n",
      " [ 0.67860112]\n",
      " [-1.05379402]\n",
      " [-0.79307006]\n",
      " [-0.55396466]\n",
      " [-0.35281005]\n",
      " [-1.68541661]\n",
      " [ 1.29062762]\n",
      " [-1.26860522]\n",
      " [ 0.74600449]\n",
      " [-1.80954146]\n",
      " [ 1.4816037 ]\n",
      " [ 0.18633441]\n",
      " [-0.41323715]\n",
      " [-0.09164059]\n",
      " [ 0.42524267]\n",
      " [ 0.54998104]\n",
      " [ 0.74223127]\n",
      " [ 1.49743481]\n",
      " [-1.4287893 ]\n",
      " [ 0.49663459]\n",
      " [-0.2205635 ]\n",
      " [ 1.44124431]\n",
      " [-0.12763698]\n",
      " [ 1.0505485 ]\n",
      " [ 0.88843743]\n",
      " [-0.57974605]\n",
      " [-2.11571562]\n",
      " [-1.18681118]\n",
      " [-0.96414228]\n",
      " [ 0.79313986]\n",
      " [ 0.8632204 ]\n",
      " [ 0.9244199 ]\n",
      " [-0.96101203]\n",
      " [ 0.71495988]\n",
      " [-0.20104715]\n",
      " [-0.5488158 ]\n",
      " [-0.34738251]\n",
      " [-0.96822851]\n",
      " [ 1.36863448]\n",
      " [-1.17118311]\n",
      " [ 1.39102445]\n",
      " [-1.95649876]\n",
      " [ 0.72986378]\n",
      " [ 1.26289645]\n",
      " [ 0.62491932]\n",
      " [-0.97880458]\n",
      " [ 0.5047095 ]\n",
      " [ 1.42467179]\n",
      " [ 0.72206158]\n",
      " [-1.41599623]\n",
      " [-0.24749114]\n",
      " [ 1.25867409]\n",
      " [-1.04390295]\n",
      " [-1.44476772]\n",
      " [-1.81092933]\n",
      " [ 1.02606603]\n",
      " [-1.02222391]\n",
      " [ 0.15608939]\n",
      " [ 0.29198206]\n",
      " [-0.84363885]\n",
      " [ 0.84819734]\n",
      " [-0.69607395]\n",
      " [ 0.41307363]\n",
      " [-0.54338773]\n",
      " [ 1.2922986 ]\n",
      " [-0.77345206]\n",
      " [ 0.27691522]\n",
      " [ 1.36075695]\n",
      " [-1.91241446]\n",
      " [ 0.8979406 ]\n",
      " [ 0.35662818]\n",
      " [ 1.12017112]\n",
      " [ 0.33216422]\n",
      " [ 1.10204921]\n",
      " [ 1.11788757]\n",
      " [ 0.81901168]\n",
      " [ 0.08532796]\n",
      " [-1.47896869]\n",
      " [ 1.02956909]\n",
      " [-1.29941471]\n",
      " [ 0.64111278]\n",
      " [ 1.30074525]\n",
      " [-0.42867047]\n",
      " [-0.99169205]\n",
      " [ 0.4946846 ]\n",
      " [ 0.93668424]\n",
      " [-0.90593221]\n",
      " [ 0.31754898]\n",
      " [-0.96851076]\n",
      " [ 0.86080397]\n",
      " [-1.35952209]\n",
      " [ 1.11588707]\n",
      " [ 1.22685237]\n",
      " [-0.38825456]\n",
      " [-0.52024061]\n",
      " [ 0.65301016]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 1) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "dados_transformados = pt.fit_transform(dados)\n",
    "\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f129c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Ajuste de Escala\n",
    "- Ajustar a escala dos dados é importante para garantir que todas as features contribuam de maneira equilibrada para o modelo.\n",
    "\n",
    "\n",
    "### A.7 Utilizar a normalização Min-Max do sklearn para garantir que os dados estão na mesma faixa-dinâmica\n",
    "\n",
    "A normalização Min-Max escala os dados para que estejam dentro de um intervalo especificado, geralmente [0, 1].\n",
    "\n",
    "O escalonamento de características é uma etapa fundamental no pré-processamento de dados para muitos algoritmos de aprendizado de máquina. Ele ajuda a padronizar o intervalo dos dados para que diferentes características contribuam de maneira justa para a modelagem. As duas técnicas populares são:\n",
    "\n",
    "**MinMax Scaling:**\n",
    "- Transforma os dados para que os valores fiquem em um intervalo definido, geralmente entre 0 e 1.\n",
    "- Fórmula: $$  X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} $$ \n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b615ada1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:25.945139Z",
     "iopub.status.busy": "2024-08-05T10:42:25.944134Z",
     "iopub.status.idle": "2024-08-05T10:42:25.950140Z",
     "shell.execute_reply": "2024-08-05T10:42:25.950140Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[1, 2], [2, 3], [4, 5]])\n",
    "\n",
    "# Aplicar MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "# Exibir os dados normalizados\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05599116 0.        ]\n",
      " [0.22857394 0.95991146]\n",
      " [0.29076317 0.21308362]\n",
      " [0.20671434 0.17790536]\n",
      " [0.94042954 0.38358675]\n",
      " [0.82125908 0.81270747]\n",
      " [0.24392851 0.19757957]\n",
      " [0.44085211 0.96260283]\n",
      " [0.03377188 0.83815342]\n",
      " [0.94462655 0.4909235 ]\n",
      " [0.333338   0.91503715]\n",
      " [0.55781708 0.16366661]\n",
      " [0.8811734  0.55663276]\n",
      " [0.3462696  0.43545456]\n",
      " [0.93299112 0.40548671]\n",
      " [0.25047145 0.70223981]\n",
      " [0.73908116 0.24145604]\n",
      " [0.94166991 0.07068302]\n",
      " [0.17802376 0.6496362 ]\n",
      " [0.39843951 0.3098238 ]\n",
      " [0.36264303 0.13590434]\n",
      " [0.68122933 0.13365361]\n",
      " [0.94651606 0.72478487]\n",
      " [0.16627025 0.3214677 ]\n",
      " [0.81519855 0.17009394]\n",
      " [0.43032578 0.26347933]\n",
      " [0.48100596 0.70579624]\n",
      " [0.27439874 0.75091953]\n",
      " [0.79888163 0.54752255]\n",
      " [0.3475474  0.72839996]\n",
      " [0.17478281 0.39232213]\n",
      " [0.52535058 0.3204416 ]\n",
      " [0.66813642 0.06768802]\n",
      " [0.53444323 0.18232382]\n",
      " [0.76180315 0.9418155 ]\n",
      " [0.83386294 0.34147325]\n",
      " [0.30202481 0.18900801]\n",
      " [0.89155617 0.32605228]\n",
      " [0.65200469 0.39278531]\n",
      " [0.16778362 0.55423534]\n",
      " [0.88701946 0.27292509]\n",
      " [0.28136498 0.96412895]\n",
      " [0.15443556 1.        ]\n",
      " [0.72185081 0.75320643]\n",
      " [0.02406575 0.4043768 ]\n",
      " [0.39552489 0.14212519]\n",
      " [0.92066036 0.06527196]\n",
      " [0.6828022  0.04550659]\n",
      " [0.64985608 0.57817662]\n",
      " [0.01461836 0.73292775]\n",
      " [0.81444887 0.24981372]\n",
      " [0.36308958 0.96759781]\n",
      " [0.24741518 0.24666806]\n",
      " [0.53078897 0.06278045]\n",
      " [0.14875705 0.09487214]\n",
      " [0.93898037 0.73194526]\n",
      " [0.320402   0.72237374]\n",
      " [0.77082363 0.81829828]\n",
      " [0.8956087  0.45448168]\n",
      " [0.30283689 0.1808722 ]\n",
      " [0.07584816 0.3271381 ]\n",
      " [0.11215758 0.30994947]\n",
      " [0.29392498 0.30353651]\n",
      " [0.38795748 0.15794559]\n",
      " [0.39678676 0.52248893]\n",
      " [0.23765784 0.53741193]\n",
      " [0.16858031 0.05063468]\n",
      " [0.40860763 0.63920235]\n",
      " [0.27512171 0.8008716 ]\n",
      " [0.55475846 0.62334573]\n",
      " [0.70318298 0.32067086]\n",
      " [0.83993822 0.29369088]\n",
      " [0.99687335 0.12342846]\n",
      " [0.54664373 0.231498  ]\n",
      " [0.94818514 0.27614067]\n",
      " [0.18771768 0.09683198]\n",
      " [0.55777563 0.18253233]\n",
      " [0.20427295 0.11202947]\n",
      " [0.71689763 0.11259634]\n",
      " [0.37908768 0.07055952]\n",
      " [0.         0.02261828]\n",
      " [0.38461484 0.89837826]\n",
      " [0.74928932 0.34779958]\n",
      " [0.08764333 0.10257095]\n",
      " [0.01714046 0.00827216]\n",
      " [0.20291851 0.12978974]\n",
      " [0.28320009 0.61094701]\n",
      " [1.         0.29236873]\n",
      " [0.49832422 0.85942552]\n",
      " [0.69310529 0.06574577]\n",
      " [0.87804122 0.44129009]\n",
      " [0.65027815 0.70228734]\n",
      " [0.66146244 0.06223228]\n",
      " [0.49132496 0.99457569]\n",
      " [0.88520364 0.02261087]\n",
      " [0.92171045 0.1180877 ]\n",
      " [0.28596167 0.27733237]\n",
      " [0.78492715 0.40243132]\n",
      " [0.01601826 0.9380903 ]\n",
      " [0.65206388 0.34629862]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035f650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Dados de exemplo\n",
    "X_train = np.array([[1., -1., 2.],\n",
    "                    [2., 0., 0.],\n",
    "                    [0., 1., -1.]])\n",
    "\n",
    "# Aplicar Min-Max Scaling\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "print(X_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad103997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20910732 0.73965727]\n",
      " [0.03206201 0.27051212]\n",
      " [0.86087612 0.59423497]\n",
      " [0.34693995 0.49871251]\n",
      " [0.89987324 0.18820996]\n",
      " [0.27040114 0.39336815]\n",
      " [0.59273054 0.40607719]\n",
      " [0.40696168 0.30141578]\n",
      " [0.76677949 0.41751495]\n",
      " [0.94584043 0.4506106 ]\n",
      " [0.37449353 0.99320806]\n",
      " [0.99048986 0.16808314]\n",
      " [0.45808735 0.35376673]\n",
      " [0.60428117 0.63443059]\n",
      " [0.54232974 0.25303889]\n",
      " [0.18492299 0.4521966 ]\n",
      " [0.56463117 0.25577595]\n",
      " [0.78307415 0.33296075]\n",
      " [1.         0.94493962]\n",
      " [0.86960155 0.63276484]\n",
      " [0.02168494 0.33852827]\n",
      " [0.55957432 0.        ]\n",
      " [0.24339807 0.53924807]\n",
      " [0.35041591 0.57381435]\n",
      " [0.20172551 0.31602608]\n",
      " [0.04118181 0.3882013 ]\n",
      " [0.68070678 0.29069064]\n",
      " [0.86874273 0.53047162]\n",
      " [0.69645098 0.17330847]\n",
      " [0.40633642 0.22259053]\n",
      " [0.47594195 0.75870544]\n",
      " [0.10175818 0.30437883]\n",
      " [0.76109304 0.93235765]\n",
      " [0.91237653 0.87092529]\n",
      " [0.37523126 0.9877602 ]\n",
      " [0.35254266 0.06510589]\n",
      " [0.08723202 0.68966654]\n",
      " [0.94810202 0.85358139]\n",
      " [0.60683217 1.        ]\n",
      " [0.79335595 0.61124385]\n",
      " [0.78719886 0.04909736]\n",
      " [0.70522063 0.33233496]\n",
      " [0.41080953 0.93987186]\n",
      " [0.16996973 0.79980953]\n",
      " [0.         0.11543621]\n",
      " [0.76017001 0.06762082]\n",
      " [0.33555566 0.36102628]\n",
      " [0.24187894 0.04461376]\n",
      " [0.94861992 0.05809041]\n",
      " [0.09231683 0.19314775]\n",
      " [0.58513086 0.09144515]\n",
      " [0.4338536  0.87708793]\n",
      " [0.34519815 0.46180712]\n",
      " [0.73003291 0.58363585]\n",
      " [0.75736469 0.90719478]\n",
      " [0.78427779 0.11907281]\n",
      " [0.06767855 0.1004214 ]\n",
      " [0.21781649 0.98730143]\n",
      " [0.53935779 0.9658464 ]\n",
      " [0.23172092 0.31091199]\n",
      " [0.54486899 0.64899682]\n",
      " [0.7078864  0.05319134]\n",
      " [0.68193633 0.00597312]\n",
      " [0.63339673 0.54093766]\n",
      " [0.36171836 0.65758599]\n",
      " [0.58299123 0.32051057]\n",
      " [0.16951754 0.74065011]\n",
      " [0.50659749 0.00253071]\n",
      " [0.54264101 0.80993128]\n",
      " [0.45625775 0.82667405]\n",
      " [0.42835298 0.92637191]\n",
      " [0.58391708 0.74573247]\n",
      " [0.04031468 0.77213734]\n",
      " [0.18710079 0.50111016]\n",
      " [0.58498098 0.23303669]\n",
      " [0.46907361 0.12612906]\n",
      " [0.23824166 0.01048246]\n",
      " [0.14229097 0.7381625 ]\n",
      " [0.25731594 0.50530044]\n",
      " [0.07152613 0.54394519]\n",
      " [0.79358412 0.94428629]\n",
      " [0.01018633 0.43742288]\n",
      " [0.18943151 0.96755744]\n",
      " [0.64077097 0.65919451]\n",
      " [0.04968323 0.121206  ]\n",
      " [0.46519675 0.08414248]\n",
      " [0.1011186  0.55084443]\n",
      " [0.56222094 0.82120088]\n",
      " [0.6206748  0.20336379]\n",
      " [0.59296593 0.03701928]\n",
      " [0.75677662 0.41462052]\n",
      " [0.19627945 0.59490799]\n",
      " [0.39016448 0.29113699]\n",
      " [0.79053147 0.65193568]\n",
      " [0.61867271 0.95761478]\n",
      " [0.79209079 0.36570881]\n",
      " [0.24855911 0.53245984]\n",
      " [0.89281341 0.46549135]\n",
      " [0.7475012  0.57232594]\n",
      " [0.21340045 0.01064583]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415816ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A.8 Utilizar a normalização Standard Scaler\n",
    "\n",
    "A normalização `StandardScaler` padroniza os dados removendo a média e escala os dados para que tenham média igual a 0 e desvio padrão 1.\n",
    "\n",
    "**Standard (Z) Scaling:**\n",
    "\n",
    "- Fórmula: $$  X_{\\text{scaled}} = \\frac{X - \\text{mean}(X)}{\\text{std}(X)} $$ \n",
    "- Usado quando a distribuição dos dados é normal ou próxima da normal.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22a89a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:25.954135Z",
     "iopub.status.busy": "2024-08-05T10:42:25.954135Z",
     "iopub.status.idle": "2024-08-05T10:42:25.959898Z",
     "shell.execute_reply": "2024-08-05T10:42:25.959898Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.06904497 -1.06904497]\n",
      " [-0.26726124 -0.26726124]\n",
      " [ 1.33630621  1.33630621]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[1, 2], [2, 3], [4, 5]])\n",
    "\n",
    "# Aplicar StandardScaler\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "# Exibir os dados normalizados\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccb4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Dados de exemplo\n",
    "X = np.array([[1., -1., 2.],\n",
    "              [2., 0., 0.],\n",
    "              [0., 1., -1.]])\n",
    "\n",
    "# Aplicar a padronização\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbfed15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### A.9 Utilizar a regularização norma-l2\n",
    "\n",
    "A regularização L2 adiciona uma penalidade igual ao quadrado da magnitude dos coeficientes do modelo linear para evitar overfitting. Em termos de manipulação de dados, isso não afeta diretamente a transformação dos dados, mas sim o processo de ajuste do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0a85a",
   "metadata": {},
   "source": [
    "![alt text](0_Rw_bC-1ByKfHvELn.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7d149",
   "metadata": {},
   "source": [
    "$$ l1, Lasso: soma dos quadrados dos resíduos + penalidade * | inclinação | $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4305e9fe",
   "metadata": {},
   "source": [
    "![alt text](0_Zy-M3ejNdZxpeIv6.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06adc471",
   "metadata": {},
   "source": [
    "$$ l2, Ridge: soma dos quadrados dos resíduos + penalidade * (inclinação)² $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be67914",
   "metadata": {},
   "source": [
    "![alt text](0_Sxd9ERNyv-yrKGvd.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc7254",
   "metadata": {},
   "source": [
    "![alt text](0_Wlq4yf-bvJWSy7Oo.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401ce10",
   "metadata": {},
   "source": [
    "\n",
    "**Exemplo usando `Ridge` do sklearn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "693cd43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:25.963900Z",
     "iopub.status.busy": "2024-08-05T10:42:25.963900Z",
     "iopub.status.idle": "2024-08-05T10:42:26.337139Z",
     "shell.execute_reply": "2024-08-05T10:42:26.337139Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 1.4]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Dados de exemplo (X: features, y: target)\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Aplicar Ridge Regression com regularização L2\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Coeficientes do modelo\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06236d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07038194  0.17457162]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Dados de exemplo\n",
    "X = np.random.rand(100, 2)  # 100 exemplos, 2 features\n",
    "y = np.random.rand(100)  # 100 valores alvo\n",
    "\n",
    "# Aplicar Ridge Regression com regularização L2\n",
    "modelo = Ridge(alpha=1.0)\n",
    "modelo.fit(X, y)\n",
    "\n",
    "print(modelo.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13334248",
   "metadata": {},
   "source": [
    "## A.10. Selecionar as features úteis para o modelo usando uma das três técnicas: Filtragem, Wrapper e Embedding\n",
    "\n",
    "A seleção de características é um passo crítico no pré-processamento de dados para aprendizado de máquina. Reduz a complexidade do modelo, diminui o tempo de treinamento e pode melhorar o desempenho do modelo ao eliminar características irrelevantes ou redundantes. Existem três abordagens principais para a seleção de características: Filtragem, Métodos Wrapper e Métodos Embutidos.\n",
    "\n",
    "\n",
    "- **Filtragem:** Seleciona as features com base em estatísticas univariadas, como a correlação.\n",
    "- **Wrapper:** Usa um modelo de machine learning para avaliar a importância de cada subset de features.\n",
    "- **Embedding:** As features são selecionadas durante o treinamento do modelo, como nos modelos baseados em árvores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077997da",
   "metadata": {},
   "source": [
    "\n",
    "#### A.10.1 Filtragem\n",
    "A abordagem de filtragem envolve a avaliação de cada característica individualmente em relação à variável de resposta e a seleção das características mais relevantes. Métodos comuns incluem:\n",
    "- **Correlação:** Mede a relação linear entre a característica e a variável de resposta. Características com alta correlação positiva ou negativa podem ser selecionadas.\n",
    "- **Informação Mútua:** Mede a dependência mútua entre a característica e a variável de resposta. Características com alta informação mútua são preferidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0934b2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **Filtragem**: Seleção de features baseada em métodos estatísticos. \n",
    "   \n",
    "- Exemplo com `SelectKBest`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc51fa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:26.341086Z",
     "iopub.status.busy": "2024-08-05T10:42:26.340086Z",
     "iopub.status.idle": "2024-08-05T10:42:26.368026Z",
     "shell.execute_reply": "2024-08-05T10:42:26.368026Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Dados de exemplo (X: features, y: target)\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Selecionar as 5 melhores features\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Features selecionadas\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Carregar dados de exemplo\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Selecionar as 2 melhores features\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_novas = selector.fit_transform(X, y)\n",
    "\n",
    "print(X_novas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3fe81",
   "metadata": {},
   "source": [
    "\n",
    "Exemplo de uso de correlação em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58881812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1    1.0\n",
      "target      1.0\n",
      "feature2   -1.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [5, 4, 3, 2, 1],\n",
    "    'target': [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "# Calcular a correlação entre características e a variável de resposta\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix['target'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6ede3",
   "metadata": {},
   "source": [
    "#### A.10.2 Métodos Wrapper\n",
    "\n",
    "Os métodos wrapper avaliam várias combinações de características e selecionam a combinação que resulta no melhor desempenho do modelo. São computacionalmente caros, mas podem ser muito eficazes. Um exemplo comum é a Regressão Stepwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f5d79c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. **Wrapper**: Seleção de features usando um modelo preditivo. Exemplo com `RFE`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e2666e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:26.373025Z",
     "iopub.status.busy": "2024-08-05T10:42:26.373025Z",
     "iopub.status.idle": "2024-08-05T10:42:26.376752Z",
     "shell.execute_reply": "2024-08-05T10:42:26.376752Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Dados de exemplo (X: features, y: target)\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "# Aplicar RFE com Logistic Regression\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "X_new = rfe.fit_transform(X, y)\n",
    "\n",
    "# Features selecionadas\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcf945",
   "metadata": {},
   "source": [
    "Exemplo de uso de um método wrapper em Python (Sequential Feature Selector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dados de exemplo\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Modelo base\n",
    "model = LinearRegression()\n",
    "\n",
    "# Sequential Feature Selector\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=1, direction='forward')\n",
    "sfs.fit(X, y)\n",
    "\n",
    "print(sfs.get_support())  # Características selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf26dc8",
   "metadata": {},
   "source": [
    "#### A.10.3 Métodos Embutidos\n",
    "\n",
    "Os métodos embutidos realizam a seleção de características durante o processo de treinamento do modelo. Exemplos incluem Árvores de Decisão e Florestas Aleatórias, que calculam a importância das características durante o ajuste do modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872da8f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **Embedding**: Seleção de features integrada ao processo de treinamento. Exemplo com `Lasso`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa2ff81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T10:42:26.381751Z",
     "iopub.status.busy": "2024-08-05T10:42:26.381751Z",
     "iopub.status.idle": "2024-08-05T10:42:26.386384Z",
     "shell.execute_reply": "2024-08-05T10:42:26.386384Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.03439734  0.          0.          0.          0.08056253\n",
      "  0.          0.          0.13757697 -0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Dados de exemplo (X: features, y: target)\n",
    "X = np.random.randn(100, 10)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# Aplicar Lasso para seleção de features\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Coeficientes do modelo\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfce186",
   "metadata": {},
   "source": [
    "Exemplo de uso de uma Árvore de Decisão em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a94681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.05]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Modelo de Árvore de Decisão\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Ajuste do modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Importâncias das características\n",
    "importances = model.feature_importances_\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd1b67",
   "metadata": {},
   "source": [
    "Exemplo de uso de Floresta Aleatória em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7264894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08491853 0.10112385 0.08774692 0.09716454 0.08359146 0.12087978\n",
      " 0.08468217 0.12909016 0.13607203 0.07473056]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(100, 10)\n",
    "y = np.random.randint(0, 2, 100)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67adf8f0",
   "metadata": {},
   "source": [
    "## A.11. Advanced Feature Selection (Seleção de Características Avançadas)\n",
    "\n",
    "#### A.11.1. Filtragem\n",
    "A abordagem de filtragem envolve a avaliação de cada característica individualmente em relação à variável de resposta e a seleção das características mais relevantes. Métodos comuns incluem:\n",
    "- **Correlação:** Mede a relação linear entre a característica e a variável de resposta. Características com alta correlação positiva ou negativa podem ser selecionadas.\n",
    "- **Informação Mútua:** Mede a dependência mútua entre a característica e a variável de resposta. Características com alta informação mútua são preferidas.\n",
    "\n",
    "Exemplo de uso de correlação em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf8a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature1    1.0\n",
      "target      1.0\n",
      "feature2   -1.0\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 5],\n",
    "    'feature2': [5, 4, 3, 2, 1],\n",
    "    'target': [1, 2, 3, 4, 5]\n",
    "})\n",
    "\n",
    "# Calcular a correlação entre características e a variável de resposta\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix['target'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f66a23",
   "metadata": {},
   "source": [
    "#### A.11.2 Métodos Wrapper\n",
    "Os métodos wrapper avaliam várias combinações de características e selecionam a combinação que resulta no melhor desempenho do modelo. São computacionalmente caros, mas podem ser muito eficazes. Um exemplo comum é a Regressão Stepwise.\n",
    "\n",
    "Exemplo de uso de um método wrapper em Python (Sequential Feature Selector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf81af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\dacio\\OneDrive\\INFNET\\machineLearning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1211: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dados de exemplo\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Modelo base\n",
    "model = LinearRegression()\n",
    "\n",
    "# Sequential Feature Selector\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=1, direction='forward')\n",
    "sfs.fit(X, y)\n",
    "\n",
    "print(sfs.get_support())  # Características selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ecfbc2",
   "metadata": {},
   "source": [
    "#### A.11.3. Métodos Embutidos\n",
    "Os métodos embutidos realizam a seleção de características durante o processo de treinamento do modelo. Exemplos incluem Árvores de Decisão e Florestas Aleatórias, que calculam a importância das características durante o ajuste do modelo.\n",
    "\n",
    "Exemplo de uso de uma Árvore de Decisão em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c504e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.05]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Modelo de Árvore de Decisão\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# Ajuste do modelo\n",
    "model.fit(X, y)\n",
    "\n",
    "# Importâncias das características\n",
    "importances = model.feature_importances_\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a2e99",
   "metadata": {},
   "source": [
    "##### 5.2.1. Seleção Univariada com SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selecionadas:\n",
      " [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Selecionar as 2 melhores features\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Features Selecionadas:\\n\", X_new[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758aad4",
   "metadata": {},
   "source": [
    "##### 5.2.2. Utilizando o Método de Variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c217196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selecionadas:\n",
      " [[5.1 1.4 0.2]\n",
      " [4.9 1.4 0.2]\n",
      " [4.7 1.3 0.2]\n",
      " [4.6 1.5 0.2]\n",
      " [5.  1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Aplicar threshold de variância\n",
    "selector = VarianceThreshold(threshold=0.2)\n",
    "X_new = selector.fit_transform(X)\n",
    "\n",
    "print(\"Features Selecionadas:\\n\", X_new[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e7d7f",
   "metadata": {},
   "source": [
    "#### 5.3. Wrapper\n",
    "As técnicas de Wrapper utilizam um modelo preditivo para avaliar a combinação de features, selecionando o subconjunto que resulta na melhor performance do modelo.\n",
    "\n",
    "##### 5.3.1. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4928c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Selecionadas:\n",
      " [[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Criar o modelo de Regressão Logística\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Aplicar RFE para selecionar 2 melhores features\n",
    "rfe = RFE(estimator=model, n_features_to_select=2)\n",
    "X_new = rfe.fit_transform(X, y)\n",
    "\n",
    "print(\"Features Selecionadas:\\n\", X_new[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e5194",
   "metadata": {},
   "source": [
    "#### 5.4. Embedding\n",
    "As técnicas de Embedding integram a seleção de features no próprio processo de treinamento do modelo. Algoritmos como Random Forest e Lasso Regression podem ser utilizados para este propósito.\n",
    "\n",
    "##### 5.4.1. Utilizando Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d79746df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Importance\n",
      "3   petal width (cm)    0.451180\n",
      "2  petal length (cm)    0.443655\n",
      "0  sepal length (cm)    0.084342\n",
      "1   sepal width (cm)    0.020823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset Iris\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Treinar um modelo Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Importância das features\n",
    "importances = model.feature_importances_\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Criar um DataFrame para visualização\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
