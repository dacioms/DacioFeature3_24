{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# github --> dacioms/DacioFeature3_24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dacio\\onedrive\\infnet\\feature engineering\\daciofeature\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Manipular dados numéricos para algoritmos de Machine Learning\n",
    "\n",
    "## A.1. Explicar o que é uma feature e a sua relação com os modelos de machine learning\n",
    "\n",
    "Uma feature, ou característica, é uma variável de entrada usada por um modelo de machine learning para fazer previsões ou tomar decisões. As features são essenciais porque carregam a informação a partir da qual o modelo aprende. Em termos mais práticos, as features podem ser vistas como colunas em uma tabela de dados, onde cada coluna representa um tipo específico de informação (como altura, peso, idade, etc.) que pode ser usada para prever um resultado (como o risco de uma doença, a classificação de um documento, etc.). A escolha e a qualidade das features influenciam diretamente o desempenho do modelo.\n",
    "\n",
    "## A.2. Explicar o que são escalares, vetores e espaços\n",
    "\n",
    "- **Escalares:** Um escalar é um único número real ou complexo. Em machine learning, um escalar pode representar uma única medida ou valor, como a temperatura em um dado dia.\n",
    "  \n",
    "- **Vetores:** Um vetor é uma sequência de números (escalares) dispostos em uma determinada ordem. Em machine learning, vetores são frequentemente usados para representar exemplos de dados. Por exemplo, um vetor pode representar as características (features) de um paciente, como [idade, peso, pressão arterial].\n",
    "  \n",
    "- **Espaços:** Um espaço, especificamente um espaço vetorial, é um conjunto de vetores que podem ser adicionados uns aos outros e multiplicados por escalares para formar novos vetores dentro do mesmo espaço. Em machine learning, o espaço vetorial das features é onde as operações de modelagem acontecem. Este espaço pode ser de alta dimensão dependendo do número de features usadas.\n",
    "\n",
    "## A.3. Realizar discretização de variáveis contínuas por meio de quantização com bins fixos\n",
    "\n",
    "A discretização de variáveis contínuas é o processo de converter variáveis contínuas em variáveis discretas dividindo o intervalo contínuo em partes distintas chamadas \"bins\". Isso pode ser feito de várias maneiras, uma das quais é utilizando bins de largura fixa.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bin 7', 'Bin 8', 'Bin 6', 'Bin 2', 'Bin 10', ..., 'Bin 10', 'Bin 10', 'Bin 8', 'Bin 5', 'Bin 3']\n",
      "Length: 100\n",
      "Categories (10, object): ['Bin 1' < 'Bin 2' < 'Bin 3' < 'Bin 4' ... 'Bin 7' < 'Bin 8' < 'Bin 9' < 'Bin 10']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Discretização com bins de largura fixa\n",
    "bins = np.linspace(0, 100, 11)  # 10 bins de largura 10\n",
    "labels = [f'Bin {i}' for i in range(1, len(bins))]\n",
    "dados_discretizados = pd.cut(dados, bins=bins, labels=labels)\n",
    "\n",
    "print(dados_discretizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.4. Realizar discretização de variáveis contínuas por meio de quantização com bins variáveis\n",
    "\n",
    "A discretização com bins variáveis, ou \"quantiles\", divide os dados em intervalos de tal forma que cada bin contém aproximadamente o mesmo número de pontos de dados.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 4 2 3 4 4 1 4 6 3 9 5 7 9 7 6 8 6 2 2 3 0 0 5 6 9 3 6 8 3 3 5 8 9 6 4\n",
      " 2 9 1 2 7 4 0 1 2 0 9 0 1 7 4 5 9 7 7 8 4 7 3 8 2 5 1 0 9 1 6 0 2 2 6 8 8\n",
      " 5 2 0 0 5 3 5 8 1 6 1 9 6 8 5 7 7 9 1 3 3 0 7 8 1 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Discretização com quantiles\n",
    "dados_discretizados = pd.qcut(dados, q=10, labels=False)\n",
    "\n",
    "print(dados_discretizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.5. Utilizar a FunctionTransformer do sklearn em uma variável\n",
    "\n",
    "A `FunctionTransformer` permite transformar os dados aplicando uma função customizada. Pode ser útil para aplicar transformações que não estão diretamente disponíveis nas outras classes de transformação do scikit-learn.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4]\n",
      " [ 9 16]\n",
      " [25 36]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Função customizada: quadrado dos valores\n",
    "transformer = FunctionTransformer(np.square)\n",
    "dados_transformados = transformer.transform(dados)\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.6. Utilizar a PowerTransformer do sklearn em uma variável\n",
    "\n",
    "A `PowerTransformer` aplica uma transformação de potência (Box-Cox ou Yeo-Johnson) para estabilizar a variância e tornar os dados mais gaussianos.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21446499]\n",
      " [ 0.55291767]\n",
      " [-0.60932522]\n",
      " [ 0.75696583]\n",
      " [-2.04213324]\n",
      " [ 1.35538274]\n",
      " [-0.87943757]\n",
      " [ 0.80827465]\n",
      " [-0.39742228]\n",
      " [ 1.00528409]\n",
      " [-0.68961381]\n",
      " [ 0.3865986 ]\n",
      " [-0.14983868]\n",
      " [ 1.4563869 ]\n",
      " [-1.55702704]\n",
      " [-0.70080589]\n",
      " [-1.26186561]\n",
      " [-1.94165681]\n",
      " [-0.41085797]\n",
      " [-1.69354995]\n",
      " [-1.68138496]\n",
      " [ 0.03828279]\n",
      " [-1.94460035]\n",
      " [ 0.30660875]\n",
      " [ 1.32410956]\n",
      " [ 1.12684846]\n",
      " [ 0.92015631]\n",
      " [-1.44118781]\n",
      " [ 0.46620352]\n",
      " [ 1.30053886]\n",
      " [ 1.17640226]\n",
      " [ 1.22048844]\n",
      " [-0.24719714]\n",
      " [ 0.22853176]\n",
      " [ 1.3190191 ]\n",
      " [-1.42844708]\n",
      " [ 0.22708303]\n",
      " [-0.00216608]\n",
      " [ 0.7120111 ]\n",
      " [-0.14805818]\n",
      " [-0.54252048]\n",
      " [ 0.23196783]\n",
      " [ 0.98738881]\n",
      " [ 0.77165684]\n",
      " [-0.77991759]\n",
      " [-2.00951522]\n",
      " [ 0.46979222]\n",
      " [-1.05289065]\n",
      " [-0.60636346]\n",
      " [-0.38298958]\n",
      " [ 0.69838637]\n",
      " [ 1.24638306]\n",
      " [-1.21202862]\n",
      " [-0.53567211]\n",
      " [ 0.08731038]\n",
      " [ 0.80043033]\n",
      " [-1.09048617]\n",
      " [-1.14078445]\n",
      " [ 1.39607934]\n",
      " [-1.04585152]\n",
      " [-0.33882662]\n",
      " [ 1.23785397]\n",
      " [-0.84172178]\n",
      " [ 0.84748813]\n",
      " [ 1.08157964]\n",
      " [-0.24234714]\n",
      " [ 0.82046362]\n",
      " [ 0.20827402]\n",
      " [-0.15575527]\n",
      " [-1.70575814]\n",
      " [ 0.1280168 ]\n",
      " [-0.91665174]\n",
      " [ 0.64969285]\n",
      " [ 0.32410222]\n",
      " [-0.56129103]\n",
      " [ 0.27040902]\n",
      " [ 0.96215185]\n",
      " [ 1.16923202]\n",
      " [-0.7767985 ]\n",
      " [ 1.33311295]\n",
      " [ 0.53683791]\n",
      " [ 0.41366906]\n",
      " [-0.54248542]\n",
      " [ 0.127443  ]\n",
      " [ 0.99086374]\n",
      " [-1.25354353]\n",
      " [-0.97722638]\n",
      " [-0.49270023]\n",
      " [-1.73835296]\n",
      " [-1.55435482]\n",
      " [ 0.08049064]\n",
      " [-0.07127082]\n",
      " [-0.83148689]\n",
      " [ 1.28131685]\n",
      " [ 1.3007442 ]\n",
      " [ 1.03558556]\n",
      " [ 1.54315586]\n",
      " [ 0.41833541]\n",
      " [ 1.19292514]\n",
      " [ 1.50939773]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 1) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "dados_transformados = pt.fit_transform(dados)\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.7. Utilizar a normalização Min-Max do sklearn para garantir que os dados estão na mesma faixa-dinâmica\n",
    "\n",
    "A normalização Min-Max escala os dados para que todos os valores fiquem dentro de um intervalo especificado, geralmente [0, 1].\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.61472652e-01 1.00000000e+00]\n",
      " [2.95998642e-01 4.06665898e-04]\n",
      " [5.23569917e-01 4.61598573e-01]\n",
      " [5.83122863e-01 5.52928147e-01]\n",
      " [6.22625037e-01 6.95751743e-01]\n",
      " [5.51913892e-01 7.09271449e-01]\n",
      " [6.34385187e-01 9.09188855e-01]\n",
      " [2.73773159e-01 9.00528839e-01]\n",
      " [7.08580819e-02 9.07010047e-01]\n",
      " [8.52783010e-01 2.50001218e-01]\n",
      " [4.37445935e-01 6.01299523e-01]\n",
      " [9.92256583e-01 2.75606344e-01]\n",
      " [0.00000000e+00 2.09148447e-01]\n",
      " [5.06464179e-01 3.95546295e-01]\n",
      " [7.43825856e-01 1.38567254e-02]\n",
      " [1.34147307e-01 3.44539377e-01]\n",
      " [7.81112507e-02 5.81100155e-01]\n",
      " [3.52196662e-01 6.52412133e-01]\n",
      " [3.45676358e-01 9.51344133e-01]\n",
      " [4.78238648e-01 1.17760904e-02]\n",
      " [6.43978157e-01 2.22428677e-01]\n",
      " [1.90790555e-02 5.28163390e-01]\n",
      " [5.65619353e-01 2.75911034e-01]\n",
      " [7.08745977e-01 3.45790754e-01]\n",
      " [6.76894025e-01 4.32945996e-01]\n",
      " [3.86337502e-02 5.29151647e-01]\n",
      " [9.47121242e-01 7.72638666e-02]\n",
      " [6.58893636e-01 4.59608731e-01]\n",
      " [2.38754924e-01 8.10028186e-01]\n",
      " [6.60744412e-02 5.37133622e-01]\n",
      " [7.03360565e-01 3.55365343e-01]\n",
      " [5.09471291e-01 2.33383912e-01]\n",
      " [5.28279656e-01 2.19133329e-02]\n",
      " [4.15918523e-01 6.91207274e-01]\n",
      " [7.23630076e-01 4.74739204e-01]\n",
      " [2.23010412e-01 8.12268188e-01]\n",
      " [6.42188454e-01 7.21813513e-01]\n",
      " [3.29938592e-01 7.40531647e-01]\n",
      " [9.73453278e-02 2.58976358e-01]\n",
      " [2.86239941e-01 8.00838153e-01]\n",
      " [9.58192151e-01 4.69442874e-01]\n",
      " [5.73330538e-01 1.67527578e-01]\n",
      " [7.22509455e-01 7.94161648e-01]\n",
      " [1.10578240e-01 2.61958149e-01]\n",
      " [2.39752286e-01 0.00000000e+00]\n",
      " [8.84105150e-01 8.78255865e-01]\n",
      " [7.60077635e-01 2.29269455e-01]\n",
      " [4.34005580e-01 7.76996465e-01]\n",
      " [9.96171564e-01 1.06007616e-01]\n",
      " [2.10148118e-02 3.82202207e-01]\n",
      " [6.51020908e-02 3.56634860e-01]\n",
      " [8.96522716e-01 7.13907241e-01]\n",
      " [8.18521828e-01 6.33218207e-01]\n",
      " [6.82461131e-01 2.00142331e-01]\n",
      " [1.61379772e-01 4.32768388e-01]\n",
      " [2.59985006e-01 2.46583862e-02]\n",
      " [8.76098598e-02 5.43025257e-01]\n",
      " [8.96329598e-01 2.09478799e-01]\n",
      " [6.08979421e-01 2.28078043e-01]\n",
      " [4.36347540e-01 3.81411844e-01]\n",
      " [5.58033486e-01 2.98198525e-01]\n",
      " [8.66820423e-01 3.95339758e-01]\n",
      " [3.42118479e-01 8.05856381e-01]\n",
      " [6.41229936e-01 1.69203052e-01]\n",
      " [4.06290534e-01 5.78568130e-01]\n",
      " [5.36833263e-01 6.28491773e-01]\n",
      " [3.16873743e-01 7.61937632e-01]\n",
      " [6.53122626e-01 4.46980841e-01]\n",
      " [8.99858051e-01 5.81723909e-01]\n",
      " [4.97401602e-01 9.13750895e-01]\n",
      " [9.30827960e-01 1.62002571e-01]\n",
      " [8.49716015e-01 6.74573343e-01]\n",
      " [3.84389527e-01 3.86544138e-02]\n",
      " [8.81692085e-01 9.13182494e-01]\n",
      " [6.02667187e-01 4.34093985e-01]\n",
      " [4.55037998e-01 1.76153899e-01]\n",
      " [7.89938882e-01 2.20015727e-02]\n",
      " [1.00000000e+00 6.44710812e-01]\n",
      " [2.69993602e-01 5.94752115e-01]\n",
      " [7.34447327e-01 3.71393992e-01]\n",
      " [5.60247696e-01 2.11495133e-01]\n",
      " [4.38840119e-01 8.20984812e-02]\n",
      " [2.67106302e-01 9.56187235e-01]\n",
      " [2.19621958e-01 8.60976445e-01]\n",
      " [1.58194846e-01 4.33527852e-01]\n",
      " [7.46512745e-01 5.82788513e-01]\n",
      " [5.91023616e-02 2.34976949e-01]\n",
      " [7.09120587e-01 5.35389695e-01]\n",
      " [3.16303230e-01 4.63849650e-01]\n",
      " [4.21005249e-02 3.21622309e-01]\n",
      " [6.35747324e-01 6.05996175e-01]\n",
      " [1.69057746e-01 1.63543384e-02]\n",
      " [6.19193529e-01 9.28207024e-01]\n",
      " [9.89247566e-01 2.05951221e-01]\n",
      " [9.24742130e-01 4.16530258e-01]\n",
      " [7.15217662e-01 5.88290299e-01]\n",
      " [9.35431890e-01 6.93467592e-01]\n",
      " [6.27856716e-02 8.10423676e-02]\n",
      " [4.91664277e-01 6.68808476e-01]\n",
      " [4.87368405e-01 9.55485753e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.8. Utilizar a normalização Standard Scaler\n",
    "\n",
    "A normalização com `StandardScaler` remove a média e escala os dados para que tenham desvio padrão unitário.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2577642  -1.63076983]\n",
      " [-1.74116728 -1.47502078]\n",
      " [-1.74183543 -1.57710461]\n",
      " [-1.41342315 -1.39516915]\n",
      " [-1.7054062   0.06341939]\n",
      " [ 0.57579387  0.89240279]\n",
      " [ 1.46258017  0.32965622]\n",
      " [-0.15756892  0.39134612]\n",
      " [ 0.56208871 -0.45648363]\n",
      " [-1.45754339 -1.71177836]\n",
      " [ 0.68433695 -0.75223574]\n",
      " [ 1.37479187 -1.66442916]\n",
      " [-1.4709398  -1.01545739]\n",
      " [ 0.95825995  1.04309566]\n",
      " [-0.70010044 -0.26418694]\n",
      " [-0.10864933 -1.55620877]\n",
      " [-1.14026368  0.81630792]\n",
      " [-0.34362829 -0.19350138]\n",
      " [-0.60154853  1.01461534]\n",
      " [-0.14717891 -1.71310896]\n",
      " [-1.45094078  1.48592352]\n",
      " [-1.3304895   0.76462304]\n",
      " [-0.67368209  0.85295612]\n",
      " [-0.37369236 -1.09178741]\n",
      " [-0.02833043  0.19135633]\n",
      " [ 0.46997016  0.47965623]\n",
      " [-0.1359915  -0.73057299]\n",
      " [ 0.92430623 -0.55571126]\n",
      " [ 1.50081564  0.93632524]\n",
      " [-0.24979896  1.2009336 ]\n",
      " [-0.03398342  1.08148793]\n",
      " [-1.02338728 -1.10097438]\n",
      " [ 0.34521764 -0.05117123]\n",
      " [-0.19944888  1.33891333]\n",
      " [-1.02300945 -0.79865303]\n",
      " [-0.88567709 -0.81977915]\n",
      " [ 0.12709243  1.13067873]\n",
      " [ 0.15599532  1.50833223]\n",
      " [ 1.37470096  1.46414681]\n",
      " [ 1.37337589 -1.09077302]\n",
      " [-0.82932331  0.55087466]\n",
      " [ 0.60367138  1.21719628]\n",
      " [ 0.50596902 -0.15121108]\n",
      " [ 0.67053456  1.0104865 ]\n",
      " [-0.52483473  0.84404288]\n",
      " [ 0.65402207  1.00700734]\n",
      " [-1.12799227  1.43660354]\n",
      " [ 1.50690155  0.98500316]\n",
      " [-1.78518227  0.34401284]\n",
      " [ 0.17486599  0.83157159]\n",
      " [-0.85250887 -1.30770257]\n",
      " [ 1.22126941 -0.32910692]\n",
      " [ 0.19995835  0.87025124]\n",
      " [ 0.25259051 -1.19926486]\n",
      " [-1.0595817   0.33257043]\n",
      " [-0.50205297  1.03512572]\n",
      " [ 1.00996519 -1.63934247]\n",
      " [-1.39374605 -0.66064668]\n",
      " [ 0.04704318 -0.8956035 ]\n",
      " [ 1.24338424 -1.71092413]\n",
      " [ 1.1585195   1.02216428]\n",
      " [ 0.86178191  0.52829104]\n",
      " [-1.32473834 -1.28673919]\n",
      " [-1.47373889  0.26278244]\n",
      " [-0.91685114 -0.65885139]\n",
      " [-0.9271346  -1.43908752]\n",
      " [-0.91101989 -0.02091358]\n",
      " [ 0.45574482 -0.02911595]\n",
      " [ 0.02621127 -1.18446492]\n",
      " [ 1.00696967  1.26945053]\n",
      " [-0.31825468  0.28091817]\n",
      " [-1.30710444  0.98706979]\n",
      " [-0.0193219  -1.00261367]\n",
      " [ 0.83885938 -0.3092553 ]\n",
      " [ 0.67709474  0.52984587]\n",
      " [ 1.07070131 -0.16562079]\n",
      " [-0.00536009  0.3834765 ]\n",
      " [ 1.02009816  0.01497338]\n",
      " [ 1.39446614  0.91768634]\n",
      " [ 1.51429904 -0.86587988]\n",
      " [-1.14879079  0.79823332]\n",
      " [-1.03767091  0.69631553]\n",
      " [-0.97395906  0.49716291]\n",
      " [-0.17906064 -0.76891732]\n",
      " [-0.68219161  0.82528068]\n",
      " [ 1.32406608  0.31848424]\n",
      " [-1.00021349 -1.25529885]\n",
      " [-1.27138425  0.95072082]\n",
      " [ 1.21361894  0.98484548]\n",
      " [-0.85570471  1.19956966]\n",
      " [ 1.32374919 -1.03012025]\n",
      " [ 1.14272494  0.8127895 ]\n",
      " [ 0.93420122 -1.24720554]\n",
      " [ 0.43686563  0.94783342]\n",
      " [ 0.96637102 -1.07961752]\n",
      " [ 1.61807768  1.54338827]\n",
      " [ 1.14916803  1.14329782]\n",
      " [ 1.10222076 -1.27358015]\n",
      " [-1.13950343  0.15879885]\n",
      " [ 1.23183524 -1.36834035]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.9. Utilizar a regularização norma-l2\n",
    "\n",
    "A regularização L2, também conhecida como regularização de Ridge, adiciona uma penalidade igual ao quadrado da magnitude dos coeficientes ao objetivo de otimização.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09073072 -0.04765239]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Dados de exemplo\n",
    "X = np.random.rand(100, 2)  # 100 exemplos, 2 features\n",
    "y = np.random.rand(100)  # 100 valores alvo\n",
    "\n",
    "# Aplicar Ridge Regression com regularização L2\n",
    "modelo = Ridge(alpha=1.0)\n",
    "modelo.fit(X, y)\n",
    "\n",
    "print(modelo.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.10. Selecionar as features úteis para o modelo usando uma das três técnicas: Filtragem, Wrapper e Embedding\n",
    "\n",
    "- **Filtragem:** Seleciona as features com base em estatísticas univariadas, como a correlação.\n",
    "- **Wrapper:** Usa um modelo de machine learning para avaliar a importância de cada subset de features.\n",
    "- **Embedding:** As features são selecionadas durante o treinamento do modelo, como nos modelos baseados em árvores.\n",
    "\n",
    "**Exemplo em Python (Filtragem):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Carregar dados de exemplo\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Selecionar as 2 melhores features\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_novas = selector.fit_transform(X, y)\n",
    "\n",
    "print(X_novas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Manipular dados numéricos para algoritmos de Machine Learning\n",
    "\n",
    "A.1. Explicar o que é uma feature e a sua relação com os modelos de machine learning\n",
    "\n",
    "**Definição:** \n",
    "Uma feature, ou característica, é uma variável de entrada usada por um modelo de machine learning para fazer previsões ou tomar decisões. As features são essenciais porque carregam a informação a partir da qual o modelo aprende. Em termos mais práticos, as features podem ser vistas como colunas em uma tabela de dados, onde cada coluna representa um tipo específico de informação (como altura, peso, idade, etc.) que pode ser usada para prever um resultado (como o risco de uma doença, a classificação de um documento, etc.). A escolha e a qualidade das features influenciam diretamente o desempenho do modelo.\n",
    "\n",
    "**Exercício Prático:**\n",
    "1. Crie um dataset fictício com pelo menos 5 features (colunas) e 100 exemplos (linhas).\n",
    "2. Escolha uma variável alvo e descreva como cada feature pode potencialmente influenciar a variável alvo.\n",
    "3. Utilize um algoritmo de regressão linear para treinar um modelo utilizando as features e avalie a performance.\n",
    "\n",
    "A.2. Explicar o que são escalares, vetores e espaços\n",
    "\n",
    "**Definição:**\n",
    "- **Escalares:** Um escalar é um único número real ou complexo. Em machine learning, um escalar pode representar uma única medida ou valor, como a temperatura em um dado dia.\n",
    "- **Vetores:** Um vetor é uma sequência de números (escalares) dispostos em uma determinada ordem. Em machine learning, vetores são frequentemente usados para representar exemplos de dados. Por exemplo, um vetor pode representar as características (features) de um paciente, como [idade, peso, pressão arterial].\n",
    "- **Espaços:** Um espaço, especificamente um espaço vetorial, é um conjunto de vetores que podem ser adicionados uns aos outros e multiplicados por escalares para formar novos vetores dentro do mesmo espaço. Em machine learning, o espaço vetorial das features é onde as operações de modelagem acontecem. Este espaço pode ser de alta dimensão dependendo do número de features usadas.\n",
    "\n",
    "**Exercício Prático:**\n",
    "1. Crie uma lista de 10 números aleatórios (escalars).\n",
    "2. Transforme essa lista em um vetor.\n",
    "3. Adicione dois vetores e multiplique um vetor por um escalar.\n",
    "4. Visualize os vetores em um gráfico (se forem de 2 ou 3 dimensões) para melhor compreensão do espaço vetorial.\n",
    "\n",
    "A.3. Realizar discretização de variáveis contínuas por meio de quantização com bins fixos\n",
    "\n",
    "**Definição:**\n",
    "A discretização de variáveis contínuas é o processo de converter variáveis contínuas em variáveis discretas dividindo o intervalo contínuo em partes distintas chamadas \"bins\". Isso pode ser feito de várias maneiras, uma das quais é utilizando bins de largura fixa.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Discretização com bins de largura fixa\n",
    "bins = np.linspace(0, 100, 11)  # 10 bins de largura 10\n",
    "labels = [f'Bin {i}' for i in range(1, len(bins))]\n",
    "dados_discretizados = pd.cut(dados, bins=bins, labels=labels)\n",
    "\n",
    "print(dados_discretizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Gere um conjunto de 200 valores contínuos aleatórios.\n",
    "2. Aplique a discretização com bins de largura fixa de modo que os valores sejam divididos em 5 categorias.\n",
    "3. Plote um histograma dos valores antes e depois da discretização.\n",
    "\n",
    "A.4. Realizar discretização de variáveis contínuas por meio de quantização com bins variáveis\n",
    "\n",
    "**Definição:**\n",
    "A discretização com bins variáveis, ou \"quantiles\", divide os dados em intervalos de tal forma que cada bin contém aproximadamente o mesmo número de pontos de dados.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Discretização com quantiles\n",
    "dados_discretizados = pd.qcut(dados, q=10, labels=False)\n",
    "\n",
    "print(dados_discretizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Utilize o mesmo conjunto de dados do exercício anterior.\n",
    "2. Aplique a discretização utilizando quantiles de forma que os dados sejam divididos em 4 categorias.\n",
    "3. Compare os resultados da discretização com bins fixos e quantiles utilizando gráficos.\n",
    "\n",
    "A.5. Utilizar a FunctionTransformer do sklearn em uma variável\n",
    "\n",
    "**Definição:**\n",
    "A `FunctionTransformer` permite transformar os dados aplicando uma função customizada. Pode ser útil para aplicar transformações que não estão diretamente disponíveis nas outras classes de transformação do scikit-learn.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Função customizada: quadrado dos valores\n",
    "transformer = FunctionTransformer(np.square)\n",
    "dados_transformados = transformer.transform(dados)\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Crie um conjunto de dados com 3 features e 50 exemplos.\n",
    "2. Aplique uma função personalizada de transformação (exemplo: logaritmo) utilizando `FunctionTransformer`.\n",
    "3. Verifique o resultado e plote os dados antes e depois da transformação.\n",
    "\n",
    "A.6. Utilizar a PowerTransformer do sklearn em uma variável\n",
    "\n",
    "**Definição:**\n",
    "A `PowerTransformer` aplica uma transformação de potência (Box-Cox ou Yeo-Johnson) para estabilizar a variância e tornar os dados mais gaussianos.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 1) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "dados_transformados = pt.fit_transform(dados)\n",
    "\n",
    "print(dados_transformados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Gere um conjunto de dados com distribuição não normal.\n",
    "2. Aplique a transformação `PowerTransformer` e verifique a distribuição resultante.\n",
    "3. Compare a distribuição dos dados antes e depois da transformação utilizando gráficos.\n",
    "\n",
    "A.7. Utilizar a normalização Min-Max do sklearn para garantir que os dados estão na mesma faixa-dinâmica\n",
    "\n",
    "**Definição:**\n",
    "A normalização Min-Max escala os dados para que todos os valores fiquem dentro de um intervalo especificado, geralmente [0, 1].\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Crie um conjunto de dados com 5 features e 200 exemplos.\n",
    "2. Aplique a normalização Min-Max para garantir que todos os dados estão na faixa [0, 1].\n",
    "3. Plote um gráfico de cada feature antes e depois da normalização.\n",
    "\n",
    "A.8. Utilizar a normalização Standard Scaler\n",
    "\n",
    "**Definição:**\n",
    "A normalização com `StandardScaler` remove a média e escala os dados para que tenham desvio padrão unitário.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dados de exemplo\n",
    "dados = np.random.rand(100, 2) * 100  # 100 valores aleatórios entre 0 e 100\n",
    "\n",
    "# Aplicar Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "dados_normalizados = scaler.fit_transform(dados)\n",
    "\n",
    "print(dados_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Crie um conjunto de dados com 4 features e 150 exemplos.\n",
    "2. Aplique a normalização `StandardScaler`.\n",
    "3. Verifique a média e o desvio padrão dos dados antes e depois da normalização.\n",
    "\n",
    "A.9. Utilizar a regularização norma-l2\n",
    "\n",
    "**Definição:**\n",
    "A regularização L2, também conhecida como regularização de Ridge, adiciona uma penalidade igual ao quadrado da magnitude dos coeficientes ao objetivo de otimização.\n",
    "\n",
    "**Exemplo em Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Dados de exemplo\n",
    "X = np.random.rand(100, 2)  # 100 exemplos, 2 features\n",
    "y = np.random.rand(100)  # 100 valores alvo\n",
    "\n",
    "# Aplicar Ridge Regression com regularização L2\n",
    "modelo = Ridge(alpha=1.0)\n",
    "modelo.fit(X, y)\n",
    "\n",
    "print(modelo.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Gere um conjunto de dados com 3 features e 100 exemplos.\n",
    "2. Aplique a regularização L2 utilizando `Ridge`.\n",
    "3. Compare os coeficientes do modelo com e sem regularização.\n",
    "\n",
    "A.10. Selecionar as features úteis para o modelo usando uma das três\n",
    "\n",
    " técnicas: Filtragem, Wrapper e Embedding\n",
    "\n",
    "**Definição:**\n",
    "- **Filtragem:** Seleciona as features com base em estatísticas univariadas, como a correlação.\n",
    "- **Wrapper:** Usa um modelo de machine learning para avaliar a importância de cada subset de features.\n",
    "- **Embedding:** As features são selecionadas durante o treinamento do modelo, como nos modelos baseados em árvores.\n",
    "\n",
    "**Exemplo em Python (Filtragem):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Carregar dados de exemplo\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Selecionar as 2 melhores features\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_novas = selector.fit_transform(X, y)\n",
    "\n",
    "print(X_novas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício Prático:**\n",
    "1. Utilize um dataset disponível no sklearn (ex: Iris).\n",
    "2. Aplique as três técnicas de seleção de features: Filtragem, Wrapper e Embedding.\n",
    "3. Compare os resultados de cada técnica e discuta as vantagens e desvantagens de cada uma.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
